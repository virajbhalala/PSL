Weekly_Pred3 = col_double()
))
# save weighted mean absolute error WMAE
num_folds <- 10
wae <- tibble(
model_one = rep(0, num_folds),
model_two = rep(0, num_folds),
model_three = rep(0, num_folds)
)
# time-series CV
for (t in 1:num_folds) {
# for (t in 1:1) {
# *** THIS IS YOUR PREDICTION FUNCTION ***
mypredict()
# Load fold file
# You should add this to your training data in the next call
# to mypredict()
fold_file <- paste0('fold_', t, '.csv')
new_test <- readr::read_csv(fold_file)
# extract predictions matching up to the current fold
scoring_tbl <- new_test %>%
left_join(test, by = c('Date', 'Store', 'Dept'))
# compute WMAE
actuals <- scoring_tbl$Weekly_Sales
preds <- select(scoring_tbl, contains('Weekly_Pred'))
weights <- if_else(scoring_tbl$IsHoliday.x, 5, 1)
wae[t, ] <- colSums(weights * abs(actuals - preds)) / sum(weights)
}
if (t > 1) {
# append the previous periods test data to the current training data
train <<- rbind(train, new_test)
}
start_date <- ymd("2011-03-01") %m+% months(2 * (t - 1))
end_date <- ymd("2011-05-01") %m+% months(2 * (t - 1))
test_month <- test %>%
filter(Date >= start_date & Date < end_date)
test_dates <- unique(test_month$Date)
num_test_dates <- length(test_dates)
all_stores <- unique(test_month$Store)
num_stores <- length(all_stores)
test_depts <- unique(test_month$Dept)
test_frame <- data.frame(
Date=rep(test_dates, num_stores),
Store=rep(all_stores, each=num_test_dates)
)
train_dates <- unique(train$Date)
num_train_dates <- length(train_dates)
train_frame <- data.frame(
Date=rep(train_dates, num_stores),
Store=rep(all_stores, each=num_train_dates)
)
if (t > 1) {
# append the previous periods test data to the current training data
train <<- rbind(train, new_test)
}
start_date <- ymd("2011-03-01") %m+% months(2 * (t - 1))
end_date <- ymd("2011-05-01") %m+% months(2 * (t - 1))
test_month <- test %>%
filter(Date >= start_date & Date < end_date)
test_dates <- unique(test_month$Date)
num_test_dates <- length(test_dates)
all_stores <- unique(test_month$Store)
num_stores <- length(all_stores)
test_depts <- unique(test_month$Dept)
test_frame <- data.frame(
Date=rep(test_dates, num_stores),
Store=rep(all_stores, each=num_test_dates)
)
train_dates <- unique(train$Date)
num_train_dates <- length(train_dates)
train_frame <- data.frame(
Date=rep(train_dates, num_stores),
Store=rep(all_stores, each=num_train_dates)
)
for (dept in test_depts) {
# filter for the particular department in the training data
train_dept_ts <- train %>%
filter(Dept == dept) %>%
select(Store, Date, Weekly_Sales)
# Reformat so that each column is a weekly time-series for that
# store's department.
# The dataframe has a shape (num_train_dates, num_stores)
train_dept_ts <- train_frame %>%
left_join(train_dept_ts, by = c('Date', 'Store')) %>%
spread(Store, Weekly_Sales)
# We create a similar dataframe to hold the forecasts on
# the dates in the testing window
test_dept_ts <- test_frame %>%
mutate(Weekly_Sales = 0) %>%
spread(Store, Weekly_Sales)
###### Model Fitting / Forecasting ######
# f_naive <- snaive_model(train_dept_ts, test_dept_ts)
# test_month <- update_forecast(test_month, f_naive, dept, 1) # 1821.882
# f_tslm <- tslm_model(train_dept_ts, test_dept_ts)
# test_month <- update_forecast(test_month, f_tslm, dept, 2) # 1611.366
f_stlf <- stlf_model(train_dept_ts, test_dept_ts)
test_month <- update_forecast(test_month, f_stlf, dept, 3) #1571.524
# f_hybrid <- autoarima_model(train_dept_ts, test_dept_ts)
# test_month <- update_forecast(test_month, f_hybrid, dept, 3) #2259.804
}
source('~/Desktop/masters/PSL/PSL/proj2/mymain.R', echo=TRUE)
train_frame <- data.frame(
Date=rep(train_dates, num_stores),
Store=rep(all_stores, each=num_train_dates)
)
train_frame <- data.frame(
Date=rep(train_dates, num_stores),
Store=rep(all_stores, each=num_train_dates)
)
if (t > 1) {
# append the previous periods test data to the current training data
train <<- rbind(train, new_test)
}
start_date <- ymd("2011-03-01") %m+% months(2 * (t - 1))
end_date <- ymd("2011-05-01") %m+% months(2 * (t - 1))
test_month <- test %>%
filter(Date >= start_date & Date < end_date)
""
if (t > 1) {
# append the previous periods test data to the current training data
train <<- rbind(train, new_test)
}
start_date <- ymd("2011-03-01") %m+% months(2 * (t - 1))
end_date <- ymd("2011-05-01") %m+% months(2 * (t - 1))
start.time <- Sys.time()
library(tidyverse)
# setwd("Desktop/Masters/PSL/PSL/proj2/")
source("mymain.R")
# read in train / test dataframes
train <- readr::read_csv('train.csv')
test <- readr::read_csv('test.csv', col_types = list(
Weekly_Pred1 = col_double(),
Weekly_Pred2 = col_double(),
Weekly_Pred3 = col_double()
))
# save weighted mean absolute error WMAE
num_folds <- 10
wae <- tibble(
model_one = rep(0, num_folds),
model_two = rep(0, num_folds),
model_three = rep(0, num_folds)
)
# time-series CV
for (t in 1:num_folds) {
# for (t in 1:1) {
# *** THIS IS YOUR PREDICTION FUNCTION ***
mypredict()
# Load fold file
# You should add this to your training data in the next call
# to mypredict()
fold_file <- paste0('fold_', t, '.csv')
new_test <- readr::read_csv(fold_file)
# extract predictions matching up to the current fold
scoring_tbl <- new_test %>%
left_join(test, by = c('Date', 'Store', 'Dept'))
# compute WMAE
actuals <- scoring_tbl$Weekly_Sales
preds <- select(scoring_tbl, contains('Weekly_Pred'))
weights <- if_else(scoring_tbl$IsHoliday.x, 5, 1)
wae[t, ] <- colSums(weights * abs(actuals - preds)) / sum(weights)
}
start.time <- Sys.time()
library(tidyverse)
# setwd("Desktop/Masters/PSL/PSL/proj2/")
source("mymain.R")
# read in train / test dataframes
train <- readr::read_csv('train.csv')
test <- readr::read_csv('test.csv', col_types = list(
Weekly_Pred1 = col_double(),
Weekly_Pred2 = col_double(),
Weekly_Pred3 = col_double()
))
# save weighted mean absolute error WMAE
num_folds <- 10
wae <- tibble(
model_one = rep(0, num_folds),
model_two = rep(0, num_folds),
model_three = rep(0, num_folds)
)
# time-series CV
for (t in 1:num_folds) {
# for (t in 1:1) {
# *** THIS IS YOUR PREDICTION FUNCTION ***
mypredict()
# Load fold file
# You should add this to your training data in the next call
# to mypredict()
fold_file <- paste0('fold_', t, '.csv')
new_test <- readr::read_csv(fold_file)
# extract predictions matching up to the current fold
scoring_tbl <- new_test %>%
left_join(test, by = c('Date', 'Store', 'Dept'))
# compute WMAE
actuals <- scoring_tbl$Weekly_Sales
preds <- select(scoring_tbl, contains('Weekly_Pred'))
weights <- if_else(scoring_tbl$IsHoliday.x, 5, 1)
wae[t, ] <- colSums(weights * abs(actuals - preds)) / sum(weights)
}
# save results to a file for grading
readr::write_csv(wae, 'Error.csv')
colMeans(wae)
end.time <- Sys.time()
time.taken <- end.time - start.time
print(paste0("time taken: ", time.taken))
start.time
start.time <- Sys.time()
start.time
start.time <- Sys.time()
library(tidyverse)
# setwd("Desktop/Masters/PSL/PSL/proj2/")
source("mymain.R")
# read in train / test dataframes
train <- readr::read_csv('train.csv')
test <- readr::read_csv('test.csv', col_types = list(
Weekly_Pred1 = col_double(),
Weekly_Pred2 = col_double(),
Weekly_Pred3 = col_double()
))
# save weighted mean absolute error WMAE
num_folds <- 10
wae <- tibble(
model_one = rep(0, num_folds),
model_two = rep(0, num_folds),
model_three = rep(0, num_folds)
)
# time-series CV
for (t in 1:num_folds) {
# for (t in 1:1) {
# *** THIS IS YOUR PREDICTION FUNCTION ***
mypredict()
# Load fold file
# You should add this to your training data in the next call
# to mypredict()
fold_file <- paste0('fold_', t, '.csv')
new_test <- readr::read_csv(fold_file)
# extract predictions matching up to the current fold
scoring_tbl <- new_test %>%
left_join(test, by = c('Date', 'Store', 'Dept'))
# compute WMAE
actuals <- scoring_tbl$Weekly_Sales
preds <- select(scoring_tbl, contains('Weekly_Pred'))
weights <- if_else(scoring_tbl$IsHoliday.x, 5, 1)
wae[t, ] <- colSums(weights * abs(actuals - preds)) / sum(weights)
}
# save results to a file for grading
readr::write_csv(wae, 'Error.csv')
colMeans(wae)
end.time <- Sys.time()
time.taken <- end.time - start.time
print(paste0("time taken: ", time.taken))
start.time
library(tidyverse)
# setwd("Desktop/Masters/PSL/PSL/proj2/")
source("mymain.R")
# read in train / test dataframes
train <- readr::read_csv('train.csv')
test <- readr::read_csv('test.csv', col_types = list(
Weekly_Pred1 = col_double(),
Weekly_Pred2 = col_double(),
Weekly_Pred3 = col_double()
))
# save weighted mean absolute error WMAE
num_folds <- 10
wae <- tibble(
model_one = rep(0, num_folds),
model_two = rep(0, num_folds),
model_three = rep(0, num_folds)
)
start.time <- Sys.time()
# time-series CV
for (t in 1:1) {
# for (t in 1:1) {
# *** THIS IS YOUR PREDICTION FUNCTION ***
mypredict()
# Load fold file
# You should add this to your training data in the next call
# to mypredict()
fold_file <- paste0('fold_', t, '.csv')
new_test <- readr::read_csv(fold_file)
# extract predictions matching up to the current fold
scoring_tbl <- new_test %>%
left_join(test, by = c('Date', 'Store', 'Dept'))
# compute WMAE
actuals <- scoring_tbl$Weekly_Sales
preds <- select(scoring_tbl, contains('Weekly_Pred'))
weights <- if_else(scoring_tbl$IsHoliday.x, 5, 1)
wae[t, ] <- colSums(weights * abs(actuals - preds)) / sum(weights)
}
# save results to a file for grading
readr::write_csv(wae, 'Error.csv')
colMeans(wae)
end.time <- Sys.time()
time.taken <- end.time - start.time
print(paste0("time taken: ", time.taken))
library(tidyverse)
# setwd("Desktop/Masters/PSL/PSL/proj2/")
source("mymain.R")
# read in train / test dataframes
train <- readr::read_csv('train.csv')
test <- readr::read_csv('test.csv', col_types = list(
Weekly_Pred1 = col_double(),
Weekly_Pred2 = col_double(),
Weekly_Pred3 = col_double()
))
# save weighted mean absolute error WMAE
num_folds <- 10
wae <- tibble(
model_one = rep(0, num_folds),
model_two = rep(0, num_folds),
model_three = rep(0, num_folds)
)
start.time <- Sys.time()
# time-series CV
for (t in 1:num_folds) {
# for (t in 1:1) {
# *** THIS IS YOUR PREDICTION FUNCTION ***
mypredict()
# Load fold file
# You should add this to your training data in the next call
# to mypredict()
fold_file <- paste0('fold_', t, '.csv')
new_test <- readr::read_csv(fold_file)
# extract predictions matching up to the current fold
scoring_tbl <- new_test %>%
left_join(test, by = c('Date', 'Store', 'Dept'))
# compute WMAE
actuals <- scoring_tbl$Weekly_Sales
preds <- select(scoring_tbl, contains('Weekly_Pred'))
weights <- if_else(scoring_tbl$IsHoliday.x, 5, 1)
wae[t, ] <- colSums(weights * abs(actuals - preds)) / sum(weights)
}
# save results to a file for grading
readr::write_csv(wae, 'Error.csv')
colMeans(wae)
end.time <- Sys.time()
time.taken <- end.time - start.time
print(paste0("time taken: ", time.taken))
start.time
end.time
library(tidyverse)
# setwd("Desktop/Masters/PSL/PSL/proj2/")
source("mymain.R")
# read in train / test dataframes
train <- readr::read_csv('train.csv')
test <- readr::read_csv('test.csv', col_types = list(
Weekly_Pred1 = col_double(),
Weekly_Pred2 = col_double(),
Weekly_Pred3 = col_double()
))
# save weighted mean absolute error WMAE
num_folds <- 10
wae <- tibble(
model_one = rep(0, num_folds),
model_two = rep(0, num_folds),
model_three = rep(0, num_folds)
)
start.time <- Sys.time()
# time-series CV
for (t in 1:num_folds) {
# for (t in 1:1) {
# *** THIS IS YOUR PREDICTION FUNCTION ***
mypredict()
# Load fold file
# You should add this to your training data in the next call
# to mypredict()
fold_file <- paste0('fold_', t, '.csv')
new_test <- readr::read_csv(fold_file)
# extract predictions matching up to the current fold
scoring_tbl <- new_test %>%
left_join(test, by = c('Date', 'Store', 'Dept'))
# compute WMAE
actuals <- scoring_tbl$Weekly_Sales
preds <- select(scoring_tbl, contains('Weekly_Pred'))
weights <- if_else(scoring_tbl$IsHoliday.x, 5, 1)
wae[t, ] <- colSums(weights * abs(actuals - preds)) / sum(weights)
}
# save results to a file for grading
readr::write_csv(wae, 'Error.csv')
colMeans(wae)
end.time <- Sys.time()
time.taken <- end.time - start.time
print(paste0("time taken: ", time.taken))
library(tidyverse)
# setwd("Desktop/Masters/PSL/PSL/proj2/")
source("mymain.R")
# read in train / test dataframes
train <- readr::read_csv('train.csv')
test <- readr::read_csv('test.csv', col_types = list(
Weekly_Pred1 = col_double(),
Weekly_Pred2 = col_double(),
Weekly_Pred3 = col_double()
))
# save weighted mean absolute error WMAE
num_folds <- 10
wae <- tibble(
model_one = rep(0, num_folds),
model_two = rep(0, num_folds),
model_three = rep(0, num_folds)
)
start.time <- Sys.time()
# time-series CV
for (t in 1:num_folds) {
# for (t in 1:1) {
# *** THIS IS YOUR PREDICTION FUNCTION ***
mypredict()
# Load fold file
# You should add this to your training data in the next call
# to mypredict()
fold_file <- paste0('fold_', t, '.csv')
new_test <- readr::read_csv(fold_file)
# extract predictions matching up to the current fold
scoring_tbl <- new_test %>%
left_join(test, by = c('Date', 'Store', 'Dept'))
# compute WMAE
actuals <- scoring_tbl$Weekly_Sales
preds <- select(scoring_tbl, contains('Weekly_Pred'))
weights <- if_else(scoring_tbl$IsHoliday.x, 5, 1)
wae[t, ] <- colSums(weights * abs(actuals - preds)) / sum(weights)
}
# save results to a file for grading
readr::write_csv(wae, 'Error.csv')
colMeans(wae)
end.time <- Sys.time()
time.taken <- end.time - start.time
print(paste0("time taken: ", time.taken))
library(tidyverse)
# setwd("Desktop/Masters/PSL/PSL/proj2/")
source("mymain.R")
# read in train / test dataframes
train <- readr::read_csv('train.csv')
test <- readr::read_csv('test.csv', col_types = list(
Weekly_Pred1 = col_double(),
Weekly_Pred2 = col_double(),
Weekly_Pred3 = col_double()
))
# save weighted mean absolute error WMAE
num_folds <- 10
wae <- tibble(
model_one = rep(0, num_folds),
model_two = rep(0, num_folds),
model_three = rep(0, num_folds)
)
start.time <- Sys.time()
# time-series CV
for (t in 1:num_folds) {
# for (t in 1:1) {
# *** THIS IS YOUR PREDICTION FUNCTION ***
mypredict()
# Load fold file
# You should add this to your training data in the next call
# to mypredict()
fold_file <- paste0('fold_', t, '.csv')
new_test <- readr::read_csv(fold_file)
# extract predictions matching up to the current fold
scoring_tbl <- new_test %>%
left_join(test, by = c('Date', 'Store', 'Dept'))
# compute WMAE
actuals <- scoring_tbl$Weekly_Sales
preds <- select(scoring_tbl, contains('Weekly_Pred'))
weights <- if_else(scoring_tbl$IsHoliday.x, 5, 1)
wae[t, ] <- colSums(weights * abs(actuals - preds)) / sum(weights)
}
# save results to a file for grading
readr::write_csv(wae, 'Error.csv')
colMeans(wae)
end.time <- Sys.time()
time.taken <- end.time - start.time
print(paste0("time taken: ", time.taken))
library(tidyverse)
# setwd("Desktop/Masters/PSL/PSL/proj2/")
source("mymain.R")
# read in train / test dataframes
train <- readr::read_csv('train.csv')
test <- readr::read_csv('test.csv', col_types = list(
Weekly_Pred1 = col_double(),
Weekly_Pred2 = col_double(),
Weekly_Pred3 = col_double()
))
# save weighted mean absolute error WMAE
num_folds <- 10
wae <- tibble(
model_one = rep(0, num_folds),
model_two = rep(0, num_folds),
model_three = rep(0, num_folds)
)
start.time <- Sys.time()
# time-series CV
for (t in 1:num_folds) {
# for (t in 1:1) {
# *** THIS IS YOUR PREDICTION FUNCTION ***
mypredict()
# Load fold file
# You should add this to your training data in the next call
# to mypredict()
fold_file <- paste0('fold_', t, '.csv')
new_test <- readr::read_csv(fold_file)
# extract predictions matching up to the current fold
scoring_tbl <- new_test %>%
left_join(test, by = c('Date', 'Store', 'Dept'))
# compute WMAE
actuals <- scoring_tbl$Weekly_Sales
preds <- select(scoring_tbl, contains('Weekly_Pred'))
weights <- if_else(scoring_tbl$IsHoliday.x, 5, 1)
wae[t, ] <- colSums(weights * abs(actuals - preds)) / sum(weights)
}
# save results to a file for grading
readr::write_csv(wae, 'Error.csv')
colMeans(wae)
end.time <- Sys.time()
time.taken <- end.time - start.time
print(paste0("time taken: ", time.taken))
wae
