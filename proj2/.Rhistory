fc.d = cast(fc.d, Date ~ Store)  # similar as tr.d
horizon = nrow(fc.d)  # number of steps ahead to forecast
for(j in 2:ncol(tr.d)){ # loop over stores
s = ts(tr.d[, j], frequency = 52)  # convert sales to time series.
fc = stlf(s, h=horizon, s.window=3, method='arima', ic='bic')
pred = as.numeric(fc$mean)
fc.d[, j] = pred
}
## If you have already unzipped the files,
train=read.csv("train.csv")
test=read.csv("test.csv")
## How many depts?
length(unique(train$Dept))
## How many stores?
length(unique(train$Store))
dept_store_train = table(train$Dept,train$Store)
dept_store_train
dept_store_test = table(test$Dept, test$Store)
dim(dept_store_train)
dim(dept_store_test)
## 11 stores in the test do not have historical data
tmp=(dept_store_train ==0 )*(dept_store_test>0)
sum(tmp)
## Names for the 81 departments
dept.names = sort(unique(train$Dept))
missing_dept_store = which(tmp>0, arr.ind=TRUE, useNames = FALSE)
missing_dept_store[,1] = dept.names[missing_dept_store[,1]]
missing_dept_store = missing_dept_store[order(missing_dept_store[,1], missing_dept_store[,2]),]
# order the missing dept+store by stores and dept
missing_dept_store
# Merge train, store, and feature
train = merge(x=train, y=store, all.x=TRUE)
train = merge(x=train, y=feature, all.x=TRUE)
test = merge(x=test, y=store, all.x=TRUE)
test = merge(x=test, y=feature, all.x=TRUE)
train$Date = as.Date(train$Date, '%Y-%m-%d')
test$Date = as.Date(test$Date, '%Y-%m-%d')
train$Yr = year(train$Date)
test$Yr = year(test$Date)
train$Mon = month(train$Date)
test$Mon = month(test$Date)
table(train$Yr, train$Mon)
table(test$Yr, test$Mon)
train.wk = train$Date
train.wk = train.wk - train.wk[1]  # date is now 0, 7, 14, ...
train.wk = train.wk/7 + 5  # make 2010-2-5 as '5', and date becomes continuous integers, i.e., 5, 6, 7, ...
train.wk = as.numeric(train.wk) %% 52  ## 52 weeks in a year
train$Wk = train.wk
test.wk = test$Date
test.wk = test.wk - test.wk[1]
test.wk = test.wk/7 + 44 # make 2012-11-02 as '44'.
test.wk = as.numeric(test.wk) %% 52
test$Wk = test.wk
table(train$Wk[train$IsHoliday])
table(test$Wk[test$IsHoliday])
################ Load Environment ##################
# clean workspace
rm(list = ls())
# load necessary packages
if (!require("pacman")) install.packages("pacman")
pacman::p_load(
"lubridate",
"forecast",
"tidyverse"
)
# converts a Date x num_store forecast to a dataframe
# with Date, Store, value = Weekly_Price columns
flatten_forecast <- function(f_model) {
f_model %>%
gather(Store, value, -Date, convert = TRUE)
}
# Adds forecasts to the testing dataframe
update_forecast <- function(test_month, dept_preds, dept, num_model) {
dept_preds <- flatten_forecast(dept_preds)
pred.d <- test_month %>%
filter(Dept == dept) %>%
select('Store', 'Date') %>%
left_join(dept_preds, by = c('Store', 'Date'))
pred.d.idx <- test_month$Dept == dept
pred.d <- test_month[pred.d.idx, c('Store', 'Date')] %>%
left_join(dept_preds, by = c('Store', 'Date'))
if (num_model == 1) {
test_month$Weekly_Pred1[pred.d.idx] <- pred.d$value
} else if(num_model == 2) {
test_month$Weekly_Pred2[pred.d.idx] <- pred.d$value
} else {
test_month$Weekly_Pred3[pred.d.idx] <- pred.d$value
}
test_month
}
# update forecasts in the global test dataframe
update_test <- function(test_month) {
test <<- test %>%
dplyr::left_join(test_month,
by = c('Date', 'Store', 'Dept', 'IsHoliday')) %>%
mutate(Weekly_Pred1 = coalesce(Weekly_Pred1.y, Weekly_Pred1.x)) %>%
mutate(Weekly_Pred2 = coalesce(Weekly_Pred2.y, Weekly_Pred2.x)) %>%
mutate(Weekly_Pred3 = coalesce(Weekly_Pred3.y, Weekly_Pred3.x)) %>%
select(-Weekly_Pred1.x, -Weekly_Pred1.y,
-Weekly_Pred2.x, -Weekly_Pred2.y,
-Weekly_Pred3.x, -Weekly_Pred3.y)
}
##### Model Building Functions #####
# Forecasts out the last observation in the training data
naive_model<- function(train_ts, test_ts){
num_forecasts <- nrow(test_ts)
train_ts[is.na(train_ts)] <- 0
# naive forecast per store
for(j in 2:ncol(train_ts)){
store_ts <- ts(train_ts[, j], frequency=52)
test_ts[, j] <- naive(store_ts, num_forecasts)$mean
}
test_ts
}
##### Prediction Loop #####
mypredict <- function() {
###### Create train and test time-series #######
if (t > 1) {
# append the previous periods test data to the current training data
train <<- rbind(train, new_test)
}
# filter test data.frame for the month that needs predictions
# backtesting starts during March 2011
start_date <- ymd("2011-03-01") %m+% months(2 * (t - 1))
end_date <- ymd("2011-05-01") %m+% months(2 * (t - 1))
test_month <- test %>%
filter(Date >= start_date & Date < end_date)
# Dates are not the same across months!
test_dates <- unique(test_month$Date)
num_test_dates <- length(test_dates)
# Not all stores may need predictions either
all_stores <- unique(test_month$Store)
num_stores <- length(all_stores)
# Most importantly not all departments need predictions
test_depts <- unique(test_month$Dept)
# Dateframe with (num_test_dates x num_stores) rows
test_frame <- data.frame(
Date=rep(test_dates, num_stores),
Store=rep(all_stores, each=num_test_dates)
)
# Create the same dataframe for the training data
# (num_train_dates x num_stores)
train_dates <- unique(train$Date)
num_train_dates <- length(train_dates)
train_frame <- data.frame(
Date=rep(train_dates, num_stores),
Store=rep(all_stores, each=num_train_dates)
)
#### Perform a individual forecasts for each department
for (dept in test_depts) {
# filter for the particular department in the training data
train_dept_ts <- train %>%
filter(Dept == dept) %>%
select(Store, Date, Weekly_Sales)
# Reformat so that each column is a weekly time-series for that
# store's department.
# The dataframe has a shape (num_train_dates, num_stores)
train_dept_ts <- train_frame %>%
left_join(train_dept_ts, by = c('Date', 'Store')) %>%
spread(Store, Weekly_Sales)
# We create a similar dataframe to hold the forecasts on
# the dates in the testing window
test_dept_ts <- test_frame %>%
mutate(Weekly_Sales = 0) %>%
spread(Store, Weekly_Sales)
###### Model Fitting / Forecasting ######
# naive forecast
f_naive <- naive_model(train_dept_ts, test_dept_ts)
test_month <- update_forecast(test_month, f_naive, dept, 1)
}
# update global test dataframe
update_test(test_month)
}
mypredict
library(tidyverse)
source("mymain.R")
# read in train / test dataframes
train <- readr::read_csv('train.csv')
test <- readr::read_csv('test.csv', col_types = list(
Weekly_Pred1 = col_double(),
Weekly_Pred2 = col_double(),
Weekly_Pred3 = col_double()
))
# save weighted mean absolute error WMAE
num_folds <- 10
wae <- tibble(
model_one = rep(0, num_folds),
model_two = rep(0, num_folds),
model_three = rep(0, num_folds)
)
# time-series CV
for (t in 1:num_folds) {
# *** THIS IS YOUR PREDICTION FUNCTION ***
mypredict()
# Load fold file
# You should add this to your training data in the next call
# to mypredict()
fold_file <- paste0('fold_', t, '.csv')
new_test <- readr::read_csv(fold_file)
# extract predictions matching up to the current fold
scoring_tbl <- new_test %>%
left_join(test, by = c('Date', 'Store', 'Dept'))
# compute WMAE
actuals <- scoring_tbl$Weekly_Sales
preds <- select(scoring_tbl, contains('Weekly_Pred'))
weights <- if_else(scoring_tbl$IsHoliday.x, 5, 1)
wae[t, ] <- colSums(weights * abs(actuals - preds)) / sum(weights)
}
# save results to a file for grading
readr::write_csv(wae, 'Error.csv')
library(tidyverse)
source("mymain.R")
# read in train / test dataframes
train <- readr::read_csv('train.csv')
test <- readr::read_csv('test.csv', col_types = list(
Weekly_Pred1 = col_double(),
Weekly_Pred2 = col_double(),
Weekly_Pred3 = col_double()
))
# save weighted mean absolute error WMAE
num_folds <- 10
wae <- tibble(
model_one = rep(0, num_folds),
model_two = rep(0, num_folds),
model_three = rep(0, num_folds)
)
setwd("Desktop/Masters/PSL/PSL/proj2/")
library(tidyverse)
source("mymain.R")
train <- readr::read_csv('train.csv')
test <- readr::read_csv('test.csv', col_types = list(
Weekly_Pred1 = col_double(),
Weekly_Pred2 = col_double(),
Weekly_Pred3 = col_double()
))
num_folds <- 10
wae <- tibble(
model_one = rep(0, num_folds),
model_two = rep(0, num_folds),
model_three = rep(0, num_folds)
)
for (t in 1:num_folds) {
# *** THIS IS YOUR PREDICTION FUNCTION ***
mypredict()
# Load fold file
# You should add this to your training data in the next call
# to mypredict()
fold_file <- paste0('fold_', t, '.csv')
new_test <- readr::read_csv(fold_file)
# extract predictions matching up to the current fold
scoring_tbl <- new_test %>%
left_join(test, by = c('Date', 'Store', 'Dept'))
# compute WMAE
actuals <- scoring_tbl$Weekly_Sales
preds <- select(scoring_tbl, contains('Weekly_Pred'))
weights <- if_else(scoring_tbl$IsHoliday.x, 5, 1)
wae[t, ] <- colSums(weights * abs(actuals - preds)) / sum(weights)
}
readr::write_csv(wae, 'Error.csv')
source("mymain.R")
num_folds <- 10
wae <- tibble(
model_one = rep(0, num_folds),
model_two = rep(0, num_folds),
model_three = rep(0, num_folds)
)
for (t in 1:num_folds) {
# *** THIS IS YOUR PREDICTION FUNCTION ***
mypredict()
# Load fold file
# You should add this to your training data in the next call
# to mypredict()
fold_file <- paste0('fold_', t, '.csv')
new_test <- readr::read_csv(fold_file)
# extract predictions matching up to the current fold
scoring_tbl <- new_test %>%
left_join(test, by = c('Date', 'Store', 'Dept'))
# compute WMAE
actuals <- scoring_tbl$Weekly_Sales
preds <- select(scoring_tbl, contains('Weekly_Pred'))
weights <- if_else(scoring_tbl$IsHoliday.x, 5, 1)
wae[t, ] <- colSums(weights * abs(actuals - preds)) / sum(weights)
}
################ Load Environment ##################
# clean workspace
rm(list = ls())
# load necessary packages
if (!require("pacman")) install.packages("pacman")
pacman::p_load(
"lubridate",
"forecast",
"tidyverse"
)
# converts a Date x num_store forecast to a dataframe
# with Date, Store, value = Weekly_Price columns
flatten_forecast <- function(f_model) {
f_model %>%
gather(Store, value, -Date, convert = TRUE)
}
# Adds forecasts to the testing dataframe
update_forecast <- function(test_month, dept_preds, dept, num_model) {
dept_preds <- flatten_forecast(dept_preds)
pred.d <- test_month %>%
filter(Dept == dept) %>%
select('Store', 'Date') %>%
left_join(dept_preds, by = c('Store', 'Date'))
pred.d.idx <- test_month$Dept == dept
pred.d <- test_month[pred.d.idx, c('Store', 'Date')] %>%
left_join(dept_preds, by = c('Store', 'Date'))
if (num_model == 1) {
test_month$Weekly_Pred1[pred.d.idx] <- pred.d$value
} else if(num_model == 2) {
test_month$Weekly_Pred2[pred.d.idx] <- pred.d$value
} else {
test_month$Weekly_Pred3[pred.d.idx] <- pred.d$value
}
test_month
}
# update forecasts in the global test dataframe
update_test <- function(test_month) {
test <<- test %>%
dplyr::left_join(test_month,
by = c('Date', 'Store', 'Dept', 'IsHoliday')) %>%
mutate(Weekly_Pred1 = coalesce(Weekly_Pred1.y, Weekly_Pred1.x)) %>%
mutate(Weekly_Pred2 = coalesce(Weekly_Pred2.y, Weekly_Pred2.x)) %>%
mutate(Weekly_Pred3 = coalesce(Weekly_Pred3.y, Weekly_Pred3.x)) %>%
select(-Weekly_Pred1.x, -Weekly_Pred1.y,
-Weekly_Pred2.x, -Weekly_Pred2.y,
-Weekly_Pred3.x, -Weekly_Pred3.y)
}
##### Model Building Functions #####
# Forecasts out the last observation in the training data
naive_model<- function(train_ts, test_ts){
num_forecasts <- nrow(test_ts)
train_ts[is.na(train_ts)] <- 0
# naive forecast per store
for(j in 2:ncol(train_ts)){
store_ts <- ts(train_ts[, j], frequency=52)
test_ts[, j] <- naive(store_ts, num_forecasts)$mean
}
test_ts
}
##### Prediction Loop #####
mypredict <- function() {
###### Create train and test time-series #######
if (t > 1) {
# append the previous periods test data to the current training data
train <<- rbind(train, new_test)
}
# filter test data.frame for the month that needs predictions
# backtesting starts during March 2011
start_date <- ymd("2011-03-01") %m+% months(2 * (t - 1))
end_date <- ymd("2011-05-01") %m+% months(2 * (t - 1))
test_month <- test %>%
filter(Date >= start_date & Date < end_date)
# Dates are not the same across months!
test_dates <- unique(test_month$Date)
num_test_dates <- length(test_dates)
# Not all stores may need predictions either
all_stores <- unique(test_month$Store)
num_stores <- length(all_stores)
# Most importantly not all departments need predictions
test_depts <- unique(test_month$Dept)
# Dateframe with (num_test_dates x num_stores) rows
test_frame <- data.frame(
Date=rep(test_dates, num_stores),
Store=rep(all_stores, each=num_test_dates)
)
# Create the same dataframe for the training data
# (num_train_dates x num_stores)
train_dates <- unique(train$Date)
num_train_dates <- length(train_dates)
train_frame <- data.frame(
Date=rep(train_dates, num_stores),
Store=rep(all_stores, each=num_train_dates)
)
#### Perform a individual forecasts for each department
for (dept in test_depts) {
# filter for the particular department in the training data
train_dept_ts <- train %>%
filter(Dept == dept) %>%
select(Store, Date, Weekly_Sales)
# Reformat so that each column is a weekly time-series for that
# store's department.
# The dataframe has a shape (num_train_dates, num_stores)
train_dept_ts <- train_frame %>%
left_join(train_dept_ts, by = c('Date', 'Store')) %>%
spread(Store, Weekly_Sales)
# We create a similar dataframe to hold the forecasts on
# the dates in the testing window
test_dept_ts <- test_frame %>%
mutate(Weekly_Sales = 0) %>%
spread(Store, Weekly_Sales)
###### Model Fitting / Forecasting ######
# naive forecast
f_naive <- naive_model(train_dept_ts, test_dept_ts)
test_month <- update_forecast(test_month, f_naive, dept, 1)
}
# update global test dataframe
update_test(test_month)
}
for (t in 1:num_folds) {
# *** THIS IS YOUR PREDICTION FUNCTION ***
mypredict()
# Load fold file
# You should add this to your training data in the next call
# to mypredict()
fold_file <- paste0('fold_', t, '.csv')
new_test <- readr::read_csv(fold_file)
# extract predictions matching up to the current fold
scoring_tbl <- new_test %>%
left_join(test, by = c('Date', 'Store', 'Dept'))
# compute WMAE
actuals <- scoring_tbl$Weekly_Sales
preds <- select(scoring_tbl, contains('Weekly_Pred'))
weights <- if_else(scoring_tbl$IsHoliday.x, 5, 1)
wae[t, ] <- colSums(weights * abs(actuals - preds)) / sum(weights)
}
num_folds <- 10
wae <- tibble(
model_one = rep(0, num_folds),
model_two = rep(0, num_folds),
model_three = rep(0, num_folds)
)
for (t in 1:num_folds) {
# *** THIS IS YOUR PREDICTION FUNCTION ***
mypredict()
# Load fold file
# You should add this to your training data in the next call
# to mypredict()
fold_file <- paste0('fold_', t, '.csv')
new_test <- readr::read_csv(fold_file)
# extract predictions matching up to the current fold
scoring_tbl <- new_test %>%
left_join(test, by = c('Date', 'Store', 'Dept'))
# compute WMAE
actuals <- scoring_tbl$Weekly_Sales
preds <- select(scoring_tbl, contains('Weekly_Pred'))
weights <- if_else(scoring_tbl$IsHoliday.x, 5, 1)
wae[t, ] <- colSums(weights * abs(actuals - preds)) / sum(weights)
}
train <- readr::read_csv('train.csv')
test <- readr::read_csv('test.csv', col_types = list(
Weekly_Pred1 = col_double(),
Weekly_Pred2 = col_double(),
Weekly_Pred3 = col_double()
))
num_folds <- 10
wae <- tibble(
model_one = rep(0, num_folds),
model_two = rep(0, num_folds),
model_three = rep(0, num_folds)
)
for (t in 1:num_folds) {
# *** THIS IS YOUR PREDICTION FUNCTION ***
mypredict()
# Load fold file
# You should add this to your training data in the next call
# to mypredict()
fold_file <- paste0('fold_', t, '.csv')
new_test <- readr::read_csv(fold_file)
# extract predictions matching up to the current fold
scoring_tbl <- new_test %>%
left_join(test, by = c('Date', 'Store', 'Dept'))
# compute WMAE
actuals <- scoring_tbl$Weekly_Sales
preds <- select(scoring_tbl, contains('Weekly_Pred'))
weights <- if_else(scoring_tbl$IsHoliday.x, 5, 1)
wae[t, ] <- colSums(weights * abs(actuals - preds)) / sum(weights)
}
wae
library(tidyverse)
source("mymain.R")
# setwd("Desktop/Masters/PSL/PSL/proj2/")
# read in train / test dataframes
train <- readr::read_csv('train.csv')
test <- readr::read_csv('test.csv', col_types = list(
Weekly_Pred1 = col_double(),
Weekly_Pred2 = col_double(),
Weekly_Pred3 = col_double()
))
# save weighted mean absolute error WMAE
num_folds <- 10
wae <- tibble(
model_one = rep(0, num_folds),
model_two = rep(0, num_folds),
model_three = rep(0, num_folds)
)
# time-series CV
for (t in 1:num_folds) {
# *** THIS IS YOUR PREDICTION FUNCTION ***
mypredict()
# Load fold file
# You should add this to your training data in the next call
# to mypredict()
fold_file <- paste0('fold_', t, '.csv')
new_test <- readr::read_csv(fold_file)
# extract predictions matching up to the current fold
scoring_tbl <- new_test %>%
left_join(test, by = c('Date', 'Store', 'Dept'))
# compute WMAE
actuals <- scoring_tbl$Weekly_Sales
preds <- select(scoring_tbl, contains('Weekly_Pred'))
weights <- if_else(scoring_tbl$IsHoliday.x, 5, 1)
wae[t, ] <- colSums(weights * abs(actuals - preds)) / sum(weights)
}
# save results to a file for grading
readr::write_csv(wae, 'Error.csv')
install.packages("pacman")
install.packages('devtools')
library(devtools)
install_github('andreacirilloac/updateR')
